{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac3513b-4e7f-462b-b41c-6e9cdd2a30f5",
   "metadata": {},
   "source": [
    "# Assignment_notebook CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c16c4c5-a687-4421-a1d4-850402f88d29",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "744344d5-4afc-4872-9e53-b39e4a52995b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T21:34:31.720954Z",
     "iopub.status.busy": "2022-05-18T21:34:31.720418Z",
     "iopub.status.idle": "2022-05-18T21:34:31.734084Z",
     "shell.execute_reply": "2022-05-18T21:34:31.733164Z",
     "shell.execute_reply.started": "2022-05-18T21:34:31.720903Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# System tools\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# Data tools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "from itertools import chain\n",
    "\n",
    "# tf tools\n",
    "import tensorflow as tf\n",
    "\n",
    "# image processsing\n",
    "from tensorflow.keras.preprocessing.image import (load_img,\n",
    "                                                  img_to_array,\n",
    "                                                  ImageDataGenerator)\n",
    "# VGG16 model\n",
    "from tensorflow.keras.applications.vgg16 import (preprocess_input,\n",
    "                                                 decode_predictions,\n",
    "                                                 VGG16)\n",
    "# layers\n",
    "from tensorflow.keras.layers import (Flatten, \n",
    "                                     Dense, \n",
    "                                     Dropout, \n",
    "                                     BatchNormalization)\n",
    "# generic model object\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# optimizers\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dc9674-4737-447e-b3e4-54c71e30d2f5",
   "metadata": {},
   "source": [
    "__Loading data__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "620823e4-0b5f-41eb-b25d-9cc5f9b96f47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T21:23:23.232741Z",
     "iopub.status.busy": "2022-05-18T21:23:23.232166Z",
     "iopub.status.idle": "2022-05-18T21:23:23.247977Z",
     "shell.execute_reply": "2022-05-18T21:23:23.246502Z",
     "shell.execute_reply.started": "2022-05-18T21:23:23.232688Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(nr_files):\n",
    "    # > load y data \n",
    "    filepath = os.path.join(\"..\", \"in\", \"processed_data\", \"y_data.npy\")\n",
    "    # Load array\n",
    "    y = np.load(filepath)\n",
    "    # Choose relevant y data  \n",
    "    y = y[:nr_files]\n",
    "    \n",
    "    # > Load file_list to be certain that X data will be in the same order as y \n",
    "    # Get the filepath\n",
    "    filepath = os.path.join(\"..\", \"in\", \"processed_data\", \"file_list.csv\")\n",
    "    # Reading the filepath \n",
    "    file_list = pd.read_csv(filepath)\n",
    "    \n",
    "    # Choose which files to load\n",
    "    y_filenames = file_list[\"files\"][:nr_files]\n",
    "    \n",
    "    # Define empthy list \n",
    "    X = []\n",
    "    # Iterate over images to load as arrays\n",
    "    for file in tqdm(y_filenames):\n",
    "        # Get filepath for image\n",
    "        filepath = os.path.join(\"..\", \"in\", \"np_arrays\", file)\n",
    "        # Load array\n",
    "        loaded_array = np.load(filepath)\n",
    "        # Append to list\n",
    "        X.append(loaded_array)\n",
    "\n",
    "    # Making sure that both X and y are numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Splitting data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size = 0.2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ed1e64bf-4df7-4f32-adf9-b154cee7ef9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:17:49.710375Z",
     "iopub.status.busy": "2022-05-18T22:17:49.709849Z",
     "iopub.status.idle": "2022-05-18T22:17:49.725438Z",
     "shell.execute_reply": "2022-05-18T22:17:49.724475Z",
     "shell.execute_reply.started": "2022-05-18T22:17:49.710326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data_nn(sample = None, size = 210):\n",
    "    # Print info\n",
    "    print(\"[INFO] Loading data...\")\n",
    "    \n",
    "    # > load y data \n",
    "    filepath = os.path.join(\"..\", \"in\", \"processed_data\", \"y_data.npy\")\n",
    "    # Load array\n",
    "    y = np.load(filepath)\n",
    "    \n",
    "    # > Load file_list to be certain that X data will be in the same order as y \n",
    "    # Get the filepath\n",
    "    filepath = os.path.join(\"..\", \"in\", \"processed_data\", \"file_list_npy.csv\")\n",
    "    # Reading the filepath \n",
    "    file_list = pd.read_csv(filepath)\n",
    "    \n",
    "    # Choose to sample or not\n",
    "    if sample: \n",
    "        # Convert y to dataframe to sample\n",
    "        y_df = pd.DataFrame(y, columns =[\"label\"])\n",
    "        # Sample and get index\n",
    "        y_sample = (y_df.groupby(\"label\", as_index=False)\n",
    "                    .apply(lambda x: x.sample(n=sample, replace=False).index)\n",
    "                    .reset_index(drop=True))\n",
    "        # Convert 2d list if indexes into 1d\n",
    "        flatten_list = list(chain.from_iterable(y_sample))\n",
    "        # Use indexes to find the y values in the sample\n",
    "        y_relevant = np.array([y[i] for i in flatten_list])\n",
    "        \n",
    "        # Define list of files to iretate over\n",
    "        y_filenames = [file_list[\"files\"].tolist()[i] for i in flatten_list]\n",
    "    else:\n",
    "        # Define list of files to iretate over\n",
    "        y_filenames = file_list[\"files\"].tolist()\n",
    "        # Define relevant y values\n",
    "        y_relevant = y\n",
    "    \n",
    "    # Define empthy list \n",
    "    X = []\n",
    "    # Iterate over images to load as arrays\n",
    "    for file in tqdm(y_filenames):\n",
    "        # Get filepath for image\n",
    "        filepath = os.path.join(\"..\", \"in\", \"np_arrays\", file)\n",
    "        # Load array\n",
    "        loaded_array = np.load(filepath)\n",
    "        # Append to list\n",
    "        X.append(loaded_array)\n",
    "\n",
    "    # Making sure that both X and y are numpy arrays\n",
    "    X = np.array(X)\n",
    "    y_relevant = np.array(y_relevant)\n",
    "\n",
    "    # Splitting data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_relevant,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size = 0.2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, y_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa4872b3-53e4-4f39-a02a-2bfa8cccd5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:18:52.629529Z",
     "iopub.status.busy": "2022-05-18T22:18:52.628998Z",
     "iopub.status.idle": "2022-05-18T22:20:58.766403Z",
     "shell.execute_reply": "2022-05-18T22:20:58.765578Z",
     "shell.execute_reply.started": "2022-05-18T22:18:52.629479Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800/2800 [02:04<00:00, 22.48it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, y_relevant = load_data_nn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a725ed55-d0ca-4628-97d5-f47f24cb26e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:14:35.346917Z",
     "iopub.status.busy": "2022-05-18T22:14:35.346390Z",
     "iopub.status.idle": "2022-05-18T22:14:35.355140Z",
     "shell.execute_reply": "2022-05-18T22:14:35.354050Z",
     "shell.execute_reply.started": "2022-05-18T22:14:35.346868Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 210, 210, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b636d071-1cba-4305-98e5-e47502a5bfb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:16:40.480830Z",
     "iopub.status.busy": "2022-05-18T22:16:40.480298Z",
     "iopub.status.idle": "2022-05-18T22:16:40.491011Z",
     "shell.execute_reply": "2022-05-18T22:16:40.489914Z",
     "shell.execute_reply.started": "2022-05-18T22:16:40.480778Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2e60d28-056b-49be-9ee6-7c1fe46bd9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:01:04.633230Z",
     "iopub.status.busy": "2022-05-18T22:01:04.632702Z",
     "iopub.status.idle": "2022-05-18T22:01:04.642769Z",
     "shell.execute_reply": "2022-05-18T22:01:04.641209Z",
     "shell.execute_reply.started": "2022-05-18T22:01:04.633180Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76c8d487-20fd-4503-98ea-64025327e355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:01:20.751427Z",
     "iopub.status.busy": "2022-05-18T22:01:20.750750Z",
     "iopub.status.idle": "2022-05-18T22:01:20.761806Z",
     "shell.execute_reply": "2022-05-18T22:01:20.760025Z",
     "shell.execute_reply.started": "2022-05-18T22:01:20.751371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test) + len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12185ce2-ce2f-4344-922d-df3e505b2513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:01:48.693124Z",
     "iopub.status.busy": "2022-05-18T22:01:48.692417Z",
     "iopub.status.idle": "2022-05-18T22:01:48.703532Z",
     "shell.execute_reply": "2022-05-18T22:01:48.701915Z",
     "shell.execute_reply.started": "2022-05-18T22:01:48.693069Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8],\n",
       "       [13],\n",
       "       [18],\n",
       "       [ 0],\n",
       "       [12],\n",
       "       [23],\n",
       "       [19],\n",
       "       [17],\n",
       "       [ 1],\n",
       "       [ 1]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "45c3e6d0-ac94-42c9-9c4f-bafb74b6ffe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:21:26.469809Z",
     "iopub.status.busy": "2022-05-18T22:21:26.469273Z",
     "iopub.status.idle": "2022-05-18T22:21:26.481225Z",
     "shell.execute_reply": "2022-05-18T22:21:26.480262Z",
     "shell.execute_reply.started": "2022-05-18T22:21:26.469761Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "21\n",
      "23\n",
      "16\n",
      "30\n",
      "22\n",
      "14\n",
      "23\n",
      "13\n",
      "17\n",
      "24\n",
      "23\n",
      "25\n",
      "24\n",
      "20\n",
      "17\n",
      "18\n",
      "21\n",
      "16\n",
      "21\n",
      "20\n",
      "20\n",
      "24\n",
      "19\n",
      "21\n",
      "19\n",
      "11\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# Lowest nr is 276\n",
    "for i in range(28):\n",
    "    print(np.count_nonzero(y_test == i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06ed8f-0c11-44ad-ad26-64365efe66b3",
   "metadata": {},
   "source": [
    "__Prepare data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8862fa0f-8d55-4be6-b290-138d5176ac93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:21:41.956998Z",
     "iopub.status.busy": "2022-05-18T22:21:41.956479Z",
     "iopub.status.idle": "2022-05-18T22:21:41.966192Z",
     "shell.execute_reply": "2022-05-18T22:21:41.964759Z",
     "shell.execute_reply.started": "2022-05-18T22:21:41.956948Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# > Prepate data\n",
    "def normalize(X_train, X_test, y_train, y_test):\n",
    "    # Normalize data \n",
    "    X_train = X_train/255\n",
    "    X_test = X_test/255\n",
    "    # Create label encodings \n",
    "    #le = LabelEncoder()\n",
    "    #y_train = le.fit_transform(y_train.ravel())\n",
    "    #y_test = le.transform(y_test.ravel())\n",
    "    # Initialize label names\n",
    "    lb = LabelBinarizer ()\n",
    "    y_train = lb.fit_transform(y_train)\n",
    "    y_test = lb.fit_transform(y_test)\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "225b835a-80c9-4b49-ad46-8ae6ce620f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:21:45.290158Z",
     "iopub.status.busy": "2022-05-18T22:21:45.289503Z",
     "iopub.status.idle": "2022-05-18T22:21:45.810836Z",
     "shell.execute_reply": "2022-05-18T22:21:45.809954Z",
     "shell.execute_reply.started": "2022-05-18T22:21:45.290099Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = normalize(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0747c879-9a4b-440b-a8db-cfacf7c635f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:21:46.576056Z",
     "iopub.status.busy": "2022-05-18T22:21:46.575417Z",
     "iopub.status.idle": "2022-05-18T22:21:46.584499Z",
     "shell.execute_reply": "2022-05-18T22:21:46.583596Z",
     "shell.execute_reply.started": "2022-05-18T22:21:46.575999Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 28)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b599da81-3ddd-4180-b917-4bcc6dda56ac",
   "metadata": {},
   "source": [
    "__Create model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "798152fa-72ec-45c9-9250-601880e39a4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:21:54.928102Z",
     "iopub.status.busy": "2022-05-18T22:21:54.927447Z",
     "iopub.status.idle": "2022-05-18T22:21:54.944149Z",
     "shell.execute_reply": "2022-05-18T22:21:54.943403Z",
     "shell.execute_reply.started": "2022-05-18T22:21:54.928042Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "861a97c5-2796-435d-b74f-1838c051c727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:21:55.394327Z",
     "iopub.status.busy": "2022-05-18T22:21:55.393751Z",
     "iopub.status.idle": "2022-05-18T22:21:55.407304Z",
     "shell.execute_reply": "2022-05-18T22:21:55.406637Z",
     "shell.execute_reply.started": "2022-05-18T22:21:55.394274Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# > Create model\n",
    "def create_model(size = 210):\n",
    "    # Print info \n",
    "    print(\"[INFO] Initializing model\")\n",
    "    \n",
    "    # > Initialize model \n",
    "    model = VGG16(include_top = False, # Do not include classifier!\n",
    "                  pooling = \"avg\", # Pooling the final layer  \n",
    "                  input_shape = (int(size), int(size), 3)) # Defineing input shape\n",
    "    # Disable training on convolutional layers\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # > Add layers \n",
    "    # The second pair of closed brackets is the input \n",
    "    flat1 = Flatten()(model.layers[-1].output) # create a flatten layer from the output for the last layer of the model\n",
    "    class1 = Dense(128, activation='relu')(flat1)\n",
    "    output = Dense(28, activation='softmax')(class1)\n",
    "    # Adding everything together\n",
    "    model = Model(inputs = model.inputs, \n",
    "                  outputs = output)\n",
    "    \n",
    "    # Print info\n",
    "    print(\"[INFO] Compiling model\")\n",
    "    # Slowing down the model's learning to avoid overfitting\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.01,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.9)\n",
    "\n",
    "    sgd = SGD(learning_rate=lr_schedule)\n",
    "    # Compiling model\n",
    "    model.compile(optimizer=sgd,\n",
    "             loss=\"categorical_crossentropy\", # binary_crossentropy for binary categories \n",
    "             metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Print info\n",
    "    print(\"[INFO] Model compiled!\")\n",
    "    print(\"[INFO] Model summary:\")\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "78e0c0df-e22d-470b-b926-0f63ea4d08c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:21:57.883221Z",
     "iopub.status.busy": "2022-05-18T22:21:57.882542Z",
     "iopub.status.idle": "2022-05-18T22:21:58.259748Z",
     "shell.execute_reply": "2022-05-18T22:21:58.259145Z",
     "shell.execute_reply.started": "2022-05-18T22:21:57.883163Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initializing model\n",
      "[INFO] Compiling model\n",
      "[INFO] Model compiled!\n",
      "[INFO] Model summary:\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 210, 210, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 210, 210, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 210, 210, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 105, 105, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 105, 105, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 105, 105, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 52, 52, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 52, 52, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 52, 52, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 52, 52, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 26, 26, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 26, 26, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 26, 26, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 26, 26, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 13, 13, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 13, 13, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 13, 13, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 13, 13, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 28)                3612      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,783,964\n",
      "Trainable params: 69,276\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c918f7e5-ee56-4197-9772-b64e5656e948",
   "metadata": {},
   "source": [
    "__Train model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eea6431d-97ad-43f1-9f6d-62bde18e61ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T22:22:03.822359Z",
     "iopub.status.busy": "2022-05-18T22:22:03.821838Z",
     "iopub.status.idle": "2022-05-18T22:23:39.217448Z",
     "shell.execute_reply": "2022-05-18T22:23:39.216691Z",
     "shell.execute_reply.started": "2022-05-18T22:22:03.822308Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "18/18 [==============================] - 32s 2s/step - loss: 3.4459 - accuracy: 0.0339 - val_loss: 3.3736 - val_accuracy: 0.0464\n",
      "Epoch 2/3\n",
      "18/18 [==============================] - 31s 2s/step - loss: 3.3726 - accuracy: 0.0362 - val_loss: 3.3531 - val_accuracy: 0.0321\n",
      "Epoch 3/3\n",
      "18/18 [==============================] - 32s 2s/step - loss: 3.3514 - accuracy: 0.0299 - val_loss: 3.3467 - val_accuracy: 0.0286\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "             validation_data = (X_test, y_test), # Was there a way to split up the validation data further?\n",
    "             batch_size = 128, # two to the power of something to optimize memory\n",
    "             epochs = 3,\n",
    "             validation_split = 0.1,\n",
    "             verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b60ef09-9296-49d8-aff4-e667c66c2f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
